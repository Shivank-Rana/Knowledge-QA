What I Used AI For:
I leveraged AI primarily to improve search results and question-answering. The AI helped generate relevant answers from the uploaded documents, select key excerpts, and present responses in a clear, concise manner. It handled the heavy lifting of understanding the content and mapping questions to the right context, which made the Knowledge Q&A experience smooth and accurate.

What I Checked Myself:
I personally verified that not all models were fully supported in Gemini, so I experimented with multiple models to find the best fit. After testing, I found that Gemini 3.0 Flash Preview worked exceptionally well for document searching and answering questions. I ensured that all queries returned correct results, UI interactions were seamless, and that the system handled edge cases like empty inputs or missing documents properly.

LLM Used:
Gemini 3.0 Flash Preview

Why I Chose This Model:
I selected this model because it is free, secure, and fast, while still delivering high-quality results across all types of documents. It provided a reliable, responsive AI backend for my app without compromising performance or security.